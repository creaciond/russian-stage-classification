{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "# custom scripts\n",
    "from data_preparation import get_X_y_type, get_X_for_rules\n",
    "from model_fitting import *\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing semantic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"./data/models/180.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.bin\")\n",
    "    model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)\n",
    "\n",
    "most_similar_entrance = set([similar[0] for similar in model.most_similar(\"входить_VERB\")])\n",
    "most_similar_exit = set([similar[0] for similar in model.most_similar(\"уходить_VERB\")])\n",
    "\n",
    "def vec_similarity(v1, v2):\n",
    "    v1_norm = gensim.matutils.unitvec(np.array(v1).astype(float))\n",
    "    v2_norm = gensim.matutils.unitvec(np.array(v2).astype(float))\n",
    "    return np.dot(v1_norm, v2_norm)\n",
    "\n",
    "def get_w2v_vectors(text, model):\n",
    "    total_counter = 0\n",
    "    total_vector = np.zeros(300)\n",
    "    for word in text:\n",
    "        try:\n",
    "            vector = np.array(model.wv[word])\n",
    "            total_vector += vector\n",
    "            total_counter += 1\n",
    "        except:\n",
    "            continue\n",
    "    res_vector = total_vector / total_counter\n",
    "    return res_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tei_type(direction):\n",
    "    tei_type = \"\"\n",
    "    verbs_list = [item for item in direction if item.endswith(\"VERB\")]\n",
    "    for verb in verbs_list:\n",
    "        # case 1 -- verb in most_common for a type\n",
    "        # in this case, we return the type immediately\n",
    "        if verb in most_similar_entrance:\n",
    "            tei_type = \"entrance\"\n",
    "            return tei_type\n",
    "        elif verb in most_similar_exit:\n",
    "            tei_type = \"exit\"\n",
    "            return tei_type\n",
    "        # case 2 -- verb is unknown\n",
    "        else:\n",
    "            direction_vector = get_w2v_vectors(verbs_list, model)\n",
    "            similarity_entrance = vec_similarity(direction_vector, model.wv[\"войти_VERB\"])\n",
    "            similarity_exit = vec_similarity(direction_vector, model.wv[\"уходить_VERB\"])\n",
    "            if similarity_entrance > similarity_exit:\n",
    "                tei_type = \"entrance\"\n",
    "            else:\n",
    "                tei_type = \"exit\"\n",
    "    return tei_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_classificator(X_list, goal_label):\n",
    "    y_list = []\n",
    "    for X in X_list:\n",
    "        label = assign_tei_type(X)\n",
    "        if label == goal_label:\n",
    "            y_list.append(1)\n",
    "        else:\n",
    "            y_list.append(0)\n",
    "    return np.array(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running classificator on all subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y_type(\"entrance\", \"train\")\n",
    "X_valid, y_valid = get_X_y_type(\"entrance\", \"val\")\n",
    "X_test, y_test = get_X_y_type(\"entrance\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for train is 0.320973\n"
     ]
    }
   ],
   "source": [
    "X_train = get_X_for_rules(\"entrance\", \"train\")\n",
    "y_pred = rule_based_classificator(X_train, \"entrance\")\n",
    "f1_train = f1_score(y_pred, y_train)\n",
    "print(\"score for train is {:.6f}\".format(f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for validation is 0.380682\n"
     ]
    }
   ],
   "source": [
    "X_valid = get_X_for_rules(\"entrance\", \"val\")\n",
    "y_pred = rule_based_classificator(X_valid, \"entrance\")\n",
    "f1_valid = f1_score(y_pred, y_valid)\n",
    "print(\"score for validation is {:.6f}\".format(f1_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y_type(\"exit\", \"train\")\n",
    "X_valid, y_valid = get_X_y_type(\"exit\", \"val\")\n",
    "X_test, y_test = get_X_y_type(\"exit\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for exit train is 0.309677\n"
     ]
    }
   ],
   "source": [
    "X_train = get_X_for_rules(\"exit\", \"train\")\n",
    "y_pred = rule_based_classificator(X_train, \"exit\")\n",
    "f1_train = f1_score(y_pred, y_train)\n",
    "print(\"score for exit train is {:.6f}\".format(f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for exit  validation is 0.311512\n"
     ]
    }
   ],
   "source": [
    "X_valid = get_X_for_rules(\"exit\", \"val\")\n",
    "y_pred = rule_based_classificator(X_valid, \"exit\")\n",
    "f1_valid = f1_score(y_pred, y_valid)\n",
    "print(\"score for exit  validation is {:.6f}\".format(f1_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 &emsp; Entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y_type(\"entrance\", \"train\")\n",
    "X_valid, y_valid = get_X_y_type(\"entrance\", \"val\")\n",
    "X_test, y_test = get_X_y_type(\"entrance\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted ML models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogReg scored 0.675830 on cross-validation with params:\n",
      "{'C': 1.1090909090909091}\n",
      "Model LogReg scored 0.834008 on validation set\n",
      "Fitting 5 folds for each of 198 candidates, totalling 990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 990 out of 990 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Decision Tree scored 0.635451 on cross-validation with params:\n",
      "{'criterion': 'gini', 'max_depth': 12}\n",
      "Model Decision Tree scored 0.888000 on validation set\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Random Forest scored 0.648480 on cross-validation with params:\n",
      "{'n_estimators': 41}\n",
      "Model Random Forest scored 0.926070 on validation set\n"
     ]
    }
   ],
   "source": [
    "entrance_dict, fitted_models = models_for_type(X_train, y_train, \n",
    "                                              X_valid, y_valid, \n",
    "                                              X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_X_for_rules(\"entrance\")\n",
    "y_rules = rule_based_classificator(X_test, \"entrance\")\n",
    "rules_score = f1_score(y_rules, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entrance_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c1d817e9118d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mentrance_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rule\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mentrance_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cross-val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_valid_rules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_based_classificator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"entrance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'entrance_dict' is not defined"
     ]
    }
   ],
   "source": [
    "entrance_dict[\"model\"].append(\"rule\")\n",
    "\n",
    "entrance_dict[\"cross-val\"].append(0)\n",
    "\n",
    "y_valid_rules = rule_based_classificator(X_valid, \"entrance\")\n",
    "valid_score = f1_score(y_valid_rules, y_valid)\n",
    "entrance_dict[\"validation\"].append(0)\n",
    "\n",
    "entrance_dict[\"test\"].append(rules_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrance_df = pd.DataFrame.from_dict(entrance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y_type(\"entrance\", \"train\")\n",
    "X_valid, y_valid = get_X_y_type(\"entrance\", \"val\")\n",
    "X_test, y_test = get_X_y_type(\"entrance\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for train is 0.320973\n"
     ]
    }
   ],
   "source": [
    "X_train = get_X_for_rules(\"entrance\", \"train\")\n",
    "y_pred = rule_based_classificator(X_train, \"entrance\")\n",
    "f1_train = f1_score(y_pred, y_train)\n",
    "print(\"score for train is {:.6f}\".format(f1_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for validation is 0.380682\n"
     ]
    }
   ],
   "source": [
    "X_valid = get_X_for_rules(\"entrance\", \"val\")\n",
    "y_pred = rule_based_classificator(X_valid, \"entrance\")\n",
    "f1_valid = f1_score(y_pred, y_valid)\n",
    "print(\"score for validation is {:.6f}\".format(f1_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fitted_models[best_model_name]\n",
    "joblib.dump(best_model, \"./data/models/entrance_final.pkl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 &emsp; Exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y_type(\"exit\", \"train\")\n",
    "X_valid, y_valid = get_X_y_type(\"exit\", \"val\")\n",
    "X_test, y_test = get_X_y_type(\"exit\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogReg scored 0.707451 on cross-validation with params:\n",
      "{'C': 0.1}\n",
      "Model LogReg scored 0.753846 on validation set\n",
      "Fitting 5 folds for each of 198 candidates, totalling 990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 990 out of 990 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Decision Tree scored 0.695571 on cross-validation with params:\n",
      "{'criterion': 'gini', 'max_depth': 6}\n",
      "Model Decision Tree scored 0.822695 on validation set\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Random Forest scored 0.717889 on cross-validation with params:\n",
      "{'n_estimators': 73}\n",
      "Model Random Forest scored 0.966887 on validation set\n"
     ]
    }
   ],
   "source": [
    "exit_dict, fitted_models = models_for_type(X_train, y_train, \n",
    "                                              X_valid, y_valid, \n",
    "                                              X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_X_for_rules(\"exit\", \"test\")\n",
    "y_test = rule_based_classificator(X_test, \"exit\")\n",
    "test_score = f1_score(y_rules, y_test)\n",
    "\n",
    "X_test = get_X_for_rules(\"exit\")\n",
    "y_test = rule_based_classificator(X_test, \"exit\")\n",
    "test_score = f1_score(y_rules, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit_dict[\"model\"].append(\"rule\")\n",
    "exit_dict[\"cross-val\"].append(test_score)\n",
    "exit_dict[\"validation\"].append(0)\n",
    "exit_dict[\"test\"].append(rules_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cross-val</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.707451</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.725552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.695571</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.713846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.717889</td>\n",
       "      <td>0.966887</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rule</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  cross-val  validation      test\n",
       "0         LogReg   0.707451    0.753846  0.725552\n",
       "1  Decision Tree   0.695571    0.822695  0.713846\n",
       "2  Random Forest   0.717889    0.966887  0.710526\n",
       "3           rule   0.000000    0.000000  0.284533"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exit_df = pd.DataFrame.from_dict(exit_dict)\n",
    "exit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n"
     ]
    }
   ],
   "source": [
    "best_model_name = exit_df.iloc[exit_df[\"test\"].argmax()][\"model\"]\n",
    "print(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = fitted_models[best_model_name]\n",
    "joblib.dump(best_model, \"./data/models/entrance_final.pkl\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
